{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63046dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b73d67",
   "metadata": {},
   "source": [
    "### README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bdae7",
   "metadata": {},
   "source": [
    "This notebook takes in user's daily bank balance data and generates user-level features.\n",
    "User features are then joined with subset labels, and two dataframes are returned:\n",
    "1) Dataframe for training of growth subset classification model (growth vs non-growth labels): 'user_features_final_growth'\n",
    "2) Dataframe for training of stable subset classification model (stable vs non-stable labels): 'user_features_final_stable'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1778b34",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users' daily balance time series data for the first 90 days\n",
    "# Columms: pt_date, user_id, total_balance\n",
    "train = pd.read_csv(\"train_data_l90d_daily_balance.csv\").sort_values(by=['pt_date', 'user_id'])\n",
    "\n",
    "# User labels generated from subsetting methodology on actual 180 days data\n",
    "# For 'label' column: 0=neither; 1=stable; 2=growth\n",
    "user_labels = pd.read_csv(\"user_subset_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b51ce4",
   "metadata": {},
   "source": [
    "### Feature engineering pt 1: generating user features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561582e",
   "metadata": {},
   "source": [
    "For new features, add a function below (e.g., get_user_features_x) and update get_all_user_features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a7facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized beta\n",
    "def get_user_features(train):\n",
    "    train_1 = train.copy().sort_values(by=[\"user_id\", \"pt_date\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Daily total balance\n",
    "    agg_balance = train_1.groupby(\"pt_date\").agg(\n",
    "        total_balance=pd.NamedAgg(column=\"total_balance\", aggfunc=\"sum\")\n",
    "    )\n",
    "    agg_balance.reset_index(inplace=True)\n",
    "\n",
    "    def z_score_normalize(column):\n",
    "        mean = column.mean()\n",
    "        std = column.std()\n",
    "        normalized_column = (column - mean) / std\n",
    "        return normalized_column\n",
    "\n",
    "    # Z-score normalise daily total balance and obtain variance\n",
    "    agg_balance[\"total_balance_normalized\"] = z_score_normalize(\n",
    "        agg_balance[\"total_balance\"]\n",
    "    )\n",
    "    agg_balance_normalized_var = agg_balance[\"total_balance_normalized\"].std() ** 2\n",
    "\n",
    "    # Loop through users to calculate normalized beta\n",
    "    user_id_list = []\n",
    "    beta_normalized_list = []\n",
    "\n",
    "    row = 0\n",
    "    for user in train[\"user_id\"].unique():\n",
    "        user_df = train.iloc[row : row + 91]\n",
    "        row += 91\n",
    "\n",
    "        # calculate beta but with normalized values\n",
    "        user_df.reset_index(inplace=True, drop=True)\n",
    "        user_df = user_df[[\"total_balance\"]]\n",
    "        user_df[\"total_balance_normalized\"] = z_score_normalize(\n",
    "            user_df[\"total_balance\"]\n",
    "        )\n",
    "        covariance_normalized = user_df[\"total_balance_normalized\"].cov(\n",
    "            agg_balance[\"total_balance_normalized\"]\n",
    "        )\n",
    "        beta_normalized_list.append(covariance_normalized / agg_balance_normalized_var)\n",
    "\n",
    "        user_id_list.append(user)\n",
    "\n",
    "    data = {\"user_id\": user_id_list, \"beta_normalized\": beta_normalized_list}\n",
    "\n",
    "    user_features = pd.DataFrame(data)\n",
    "    return user_features\n",
    "    \n",
    "    \n",
    "\n",
    "# User's first, last and average balance + last n-day EMA\n",
    "# Standard deviation of balance, CV and stability index\n",
    "def get_user_features_2(train, user_features):\n",
    "    user_features_2 = user_features.copy()\n",
    "\n",
    "    # Calculate first, last and average values of total_balance\n",
    "    user_features_2['avg_balance'] = train.groupby('user_id')['total_balance'].mean().reset_index(drop=True)\n",
    "    user_features_2['first_day_balance'] = train.groupby('user_id')['total_balance'].first().values\n",
    "    user_features_2['last_day_balance'] = train.groupby('user_id')['total_balance'].last().values\n",
    "\n",
    "    # Binning of user balance\n",
    "    bins = [-1, 5000, 30000, 100000, 350000, 2000000, float('inf')]\n",
    "    labels = ['Small', 'Medium', 'Big', 'Wealth Banking', 'Privilege Banking', 'Privilege Reserve']\n",
    "    user_features_2['label_by_avg_bal'] = pd.cut(user_features_2['avg_balance'], bins=bins, labels=labels)\n",
    "    user_features_2['label_by_first_bal'] = pd.cut(user_features_2['first_day_balance'], bins=bins, labels=labels)\n",
    "    user_features_2['label_by_last_bal'] = pd.cut(user_features_2['last_day_balance'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Standard Deviation, Coefficient of Variation and Stability Index\n",
    "    user_features_2['volatility_stdev'] = train.groupby('user_id')['total_balance'].std().reset_index(drop=True)\n",
    "    user_features_2['volatility_cv'] = (user_features_2['volatility_stdev'] / user_features_2['avg_balance']) * 100\n",
    "    \n",
    "    cv_scaled = (user_features_2['volatility_cv'] - min(user_features_2['volatility_cv'])) / \\\n",
    "    (max(user_features_2['volatility_cv']) - min(user_features_2['volatility_cv']))\n",
    "    user_features_2['stability_index'] = 1 - cv_scaled\n",
    "    \n",
    "    \n",
    "    # Calculate 7-day EMA, 20-day EMA, 50-day EMA and 90-day EMA (feature is the LAST n-day EMA)\n",
    "    ema_spans = [7, 20, 50, 90]\n",
    "    for span in ema_spans:\n",
    "        user_features_2[f'ema_{span}day'] = train.groupby('user_id')['total_balance'].apply(lambda x: x.ewm(span=span).mean().iloc[-1]).values\n",
    "\n",
    "    user_features_2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return user_features_2\n",
    "\n",
    "\n",
    "\n",
    "# Binary feature of whether user has statistically significant +ve kendall coefficient, \n",
    "# Indicates whether there is a positive correlation between date & balance\n",
    "# statistically significant (1% sig. level) & positive correlation -> positive trend\n",
    "def get_user_features_3(train, user_features_2):\n",
    "    kendall_coeff = train.groupby('user_id').apply(\n",
    "        lambda group: kendalltau(group['pt_date'], group['total_balance'])[0]).reset_index()\n",
    "\n",
    "    kendall_coeff.columns = ['user_id', 'kendall_coeff']\n",
    "\n",
    "    kendall_p = train.groupby('user_id').apply(\n",
    "        lambda group: kendalltau(group['pt_date'], group['total_balance'])[1]).reset_index()\n",
    "\n",
    "    kendall_p.columns = ['user_id', 'kendall_p']\n",
    "\n",
    "    kendall = kendall_coeff.merge(kendall_p, on='user_id')\n",
    "    kendall['stat_sig_positive_kendall'] = np.where((kendall['kendall_p'] < 0.01) & \\\n",
    "                                                    (kendall['kendall_coeff'] > 0), 1, 0)\n",
    "\n",
    "    user_features_3 = user_features_2.merge(kendall[['user_id', 'stat_sig_positive_kendall']], on='user_id')\n",
    "\n",
    "    return user_features_3\n",
    "\n",
    "\n",
    "\n",
    "# Number of times user's short-term EMA crosses long-term EMA\n",
    "def get_user_features_4(train, user_features_3):\n",
    "    train_2 = train.copy().sort_values(by=['user_id', 'pt_date'])\n",
    "\n",
    "    # Calculate 7-day and 50-day EMA for each user\n",
    "    train_2['ema_7day'] = train_2.groupby('user_id')['total_balance'].transform(lambda x: x.ewm(span=7).mean())\n",
    "    train_2['ema_50day'] = train_2.groupby('user_id')['total_balance'].transform(lambda x: x.ewm(span=50).mean())\n",
    "\n",
    "    # Detect EMA crossings by checking for changes in the sign of the difference\n",
    "    train_2['ema_difference'] = train_2['ema_7day'] - train_2['ema_50day']\n",
    "    train_2['ema_crosses'] = train_2['ema_difference'] * train_2['ema_difference'].shift(1) < 0 \n",
    "\n",
    "    # Count the number of crossings for each user\n",
    "    train_2['num_ema_crosses'] = train_2.groupby('user_id')['ema_crosses'].transform('sum')\n",
    "\n",
    "    # User-level dataframe\n",
    "    num_ema_crosses = train_2.groupby('user_id')['num_ema_crosses'].mean().reset_index()\n",
    "    \n",
    "    user_features_4 = user_features_3.merge(num_ema_crosses, on='user_id')\n",
    "    return user_features_4\n",
    "\n",
    "\n",
    "# Binary feature: whether user's bank balance is stationary\n",
    "# ADF test on user balance at 1% significance level\n",
    "def get_user_features_5(train, user_features_4):\n",
    "    train_3 = train.copy().sort_values(by=['user_id', 'pt_date'])\n",
    "    train_3['balance_change'] = train_3.groupby('user_id')['total_balance'].diff()\n",
    "\n",
    "    # ADF test -> return both coefficient and p-value\n",
    "    # H0: non-stationary\n",
    "\n",
    "    def adf_test(data):\n",
    "        result = adfuller(data['balance_change'].dropna())\n",
    "        adf_coefficient = result[0]\n",
    "        p_value = result[1]\n",
    "        return pd.Series({'adf_coeff': adf_coefficient, 'adf_p': p_value})\n",
    "\n",
    "    adf = train_3.groupby('user_id').apply(adf_test).reset_index()\n",
    "\n",
    "    # Binary variable for stationarity\n",
    "    adf['stationary'] = np.where(adf['adf_p'] < 0.01, 1, 0)\n",
    "    adf.columns = ['user_id', 'adf_coeff', 'adf_p', 'stationary']\n",
    "    \n",
    "    user_features_5 = user_features_4.merge(adf[['user_id', 'stationary']], on='user_id')\n",
    "    return user_features_5\n",
    "\n",
    "\n",
    "# Features relating to recurring transactions\n",
    "# Attempts to identify user traits i.e., what they are using their Maribank account for\n",
    "# Didn't explore time interval between recurring transactions;\n",
    "# Solely inferring purpose of usage based on recurring deposit/withdrawal amount for now\n",
    "# Thresholds are also subjective\n",
    "def get_user_features_6(train, user_features_5):\n",
    "\n",
    "    train_4 = train.copy().sort_values(by=['user_id', 'pt_date'])\n",
    "    train_4['balance_change'] = train_4.groupby('user_id')['total_balance'].diff()\n",
    "\n",
    "    # Round off the balance change to 2dp; \n",
    "    train_4['balance_change'] = round(train_4['balance_change'], 2)\n",
    "    \n",
    "    grouped = train_4[['user_id', 'balance_change']].groupby('user_id')['balance_change']\n",
    "    \n",
    "    user_data = []\n",
    "\n",
    "    for user, transactions in grouped:\n",
    "\n",
    "        # Count transaction amounts (excluding 0 balance change) and their frequencies\n",
    "        unique_transactions = transactions[transactions != 0].value_counts()\n",
    "\n",
    "        # Filter for recurring transactions, where count > 1\n",
    "        recurring_transactions = unique_transactions[unique_transactions > 1]\n",
    "        recurring_tx_count = (unique_transactions > 1).sum()\n",
    "        recurring_tx_amounts = []\n",
    "\n",
    "        if recurring_tx_count > 0:\n",
    "            num_distinct_recurring_tx = len(recurring_transactions)\n",
    "            \n",
    "            # List of recurring transactin for each user\n",
    "            recurring_tx_amounts = recurring_transactions.index.tolist()\n",
    "            \n",
    "        else:\n",
    "            num_distinct_recurring_tx = 0\n",
    "\n",
    "\n",
    "        user_data.append({'user_id': user, \n",
    "                          'num_distinct_recurring_tx': num_distinct_recurring_tx, \n",
    "                          'recurring_tx_amounts': recurring_tx_amounts,\n",
    "                         })\n",
    "\n",
    "    recurring_tx = pd.DataFrame(user_data)\n",
    "    \n",
    "    # Binary feature: whether user has recurring transactions\n",
    "    recurring_tx['recurring_transactions'] = np.where(recurring_tx['num_distinct_recurring_tx'] > 0, 1, 0)\n",
    "    \n",
    "    # Binary feature: whether user has recurring deposits\n",
    "    has_recurring_deposits = [any(value > 0 for value in row) for row in recurring_tx['recurring_tx_amounts']]\n",
    "    recurring_tx['recurring_deposits'] = np.where(has_recurring_deposits, 1, 0)\n",
    "    \n",
    "    # Binary feature: whether user has recurring withdrawals\n",
    "    has_recurring_withdrawals = [any(value < 0 for value in row) for row in recurring_tx['recurring_tx_amounts']]\n",
    "    recurring_tx['recurring_withdrawals'] = np.where(has_recurring_withdrawals, 1, 0)\n",
    "    \n",
    "    # Binary feature: whether user utilises bank acc for income\n",
    "    # Income defined as recurring deposits of > $1000\n",
    "    has_income = [any(value > 1000 for value in row) for row in recurring_tx['recurring_tx_amounts']]\n",
    "    recurring_tx['income'] = np.where(has_income, 1, 0)\n",
    "    \n",
    "    # Binary feature: whether user utilises bank acc to pay for subscriptions\n",
    "    # Subscription defined as recurring withdrawals of between 0 to $100\n",
    "    has_subscription = [any(-100 <= value < 0 for value in row) for row in recurring_tx['recurring_tx_amounts']]\n",
    "    recurring_tx['subscription'] = np.where(has_subscription, 1, 0)\n",
    "    \n",
    "    recurring_tx = recurring_tx.drop('recurring_tx_amounts', axis=1)\n",
    "    \n",
    "    user_features_6 = user_features_5.merge(recurring_tx, on='user_id')\n",
    "    return user_features_6\n",
    "\n",
    "\n",
    "# Absolute balance change mean and SD\n",
    "# Transaction, withdrawal, deposit counts and proportions\n",
    "def get_user_features_7(train, user_features_6):\n",
    "    train_5 = train.copy().sort_values(by=[\"user_id\", \"pt_date\"])\n",
    "    train_5[\"abs_bal_change\"] = train_5.groupby(\"user_id\")[\"total_balance\"].diff()\n",
    "    \n",
    "    train_5[\"pct_bal_change\"] = train_5.groupby(\"user_id\")[\"total_balance\"].pct_change() * 100\n",
    "    train_5[\"deposit_flag\"] = np.where(train_5[\"pct_bal_change\"] > 0.015, 1, 0)\n",
    "    train_5[\"withdrawal_flag\"] = np.where(train_5[\"pct_bal_change\"] < -0.015, 1, 0)\n",
    "    train_5[\"transaction_flag\"] = np.where((train_5[\"deposit_flag\"] == 1) | (train_5[\"withdrawal_flag\"] == 1),\n",
    "                                           1, 0)\n",
    "    \n",
    "    result = train_5.groupby(\"user_id\").agg(\n",
    "        abs_bal_change_mean=(\"abs_bal_change\", \"mean\"),\n",
    "        abs_bal_change_std=(\"abs_bal_change\", \"std\"),\n",
    "        transactions=(\"transaction_flag\", \"sum\"),\n",
    "        deposits=(\"deposit_flag\", \"sum\"),\n",
    "        withdrawals=(\"withdrawal_flag\", \"sum\")\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Set proportion = 0 if there are no transactions, otherwise calculate proportion\n",
    "    result['withdrawal_propn'] = np.where(result['transactions'] == 0, 0, result['withdrawals'] / result['transactions'])\n",
    "    result['deposit_propn'] = np.where(result['transactions'] == 0, 0, result['deposits'] / result['transactions'])\n",
    "\n",
    "    user_features_7 = user_features_6.merge(result, on='user_id')\n",
    "    return user_features_7\n",
    "\n",
    "\n",
    "\n",
    "# Growth coefficient (line of best fit of user balance) and trend\n",
    "def get_user_features_8(train, user_features_7):\n",
    "    train_6 = train.copy().sort_values(by=['user_id', 'pt_date'])\n",
    "\n",
    "    def get_growth_coeff(data):\n",
    "        x = list(range(0, 91))\n",
    "        y = data['total_balance']\n",
    "        a, b = np.polyfit(x, y, 1)\n",
    "        return pd.Series({'growth_coeff': a})\n",
    "\n",
    "    result = train_6.groupby('user_id').apply(get_growth_coeff).reset_index()\n",
    "    \n",
    "    trend_bins = [-float('inf'), -10, 10, float('inf')]\n",
    "    trend_labels = ['Decreasing', 'Stable', 'Increasing']\n",
    "    result['trend'] = pd.cut(result['growth_coeff'], bins=trend_bins, labels=trend_labels)\n",
    "    \n",
    "    user_features_8 = user_features_7.merge(result, on='user_id')\n",
    "    return user_features_8\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51cddbc",
   "metadata": {},
   "source": [
    "### Feature engineering pt2: encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5c05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_categorical_columns(user_features):\n",
    "    categorical_cols = []\n",
    "    for col in user_features.columns:\n",
    "        if (user_features[col].dtype == 'object' or user_features[col].dtype == 'category') and col != 'user_id':\n",
    "            categorical_cols.append(col)\n",
    "    \n",
    "    print(\"The categorical variables to be encoded are\")\n",
    "    print(categorical_cols)\n",
    "    \n",
    "    return categorical_cols\n",
    "\n",
    "\n",
    "def encode_categorical_features(user_features):\n",
    "    categorical_cols = identify_categorical_columns(user_features)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        user_features[col] = label_encoder.fit_transform(user_features[col])\n",
    "        \n",
    "    return user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868d07c",
   "metadata": {},
   "source": [
    "### Dataframe with all user features (w/o subset labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbfc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_user_features(train):\n",
    "    print(\"Generating user_features...\")\n",
    "    user_features = get_user_features(train)\n",
    "    \n",
    "    print(\"Generating user_features_2...\")\n",
    "    user_features_2 = get_user_features_2(train, user_features)\n",
    "    \n",
    "    print(\"Generating user_features_3...\")\n",
    "    user_features_3 = get_user_features_3(train, user_features_2)\n",
    "    \n",
    "    print(\"Generating user_features_4...\")\n",
    "    user_features_4 = get_user_features_4(train, user_features_3)\n",
    "\n",
    "    print(\"Generating user_features_5...\")\n",
    "    user_features_5 = get_user_features_5(train, user_features_4)\n",
    "    \n",
    "    print(\"Generating user_features_6...\")\n",
    "    user_features_6 = get_user_features_6(train, user_features_5)\n",
    "    \n",
    "    print(\"Generating user_features_7...\")\n",
    "    user_features_7 = get_user_features_7(train, user_features_6)\n",
    "    \n",
    "    print(\"Generating user_features_8...\")\n",
    "    user_features_8 = get_user_features_8(train, user_features_7)\n",
    "    \n",
    "    print(\"Encoding categorical variables...\")\n",
    "    user_features_final = encode_categorical_features(user_features_8)\n",
    "    \n",
    "    return user_features_final\n",
    "\n",
    "    return user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19869382",
   "metadata": {},
   "source": [
    "### Join with subset labels, obtain 2 dataframes for growth & stable classification models respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb54322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_users(user_labels, user_features_final):\n",
    "    stable_labels = user_labels[['user_id', 'is_in_stable_subset']]\\\n",
    "    .rename(columns={'is_in_stable_subset': 'label'})\n",
    "    \n",
    "    growth_labels = user_labels[['user_id', 'is_in_growth_subset']]\\\n",
    "    .rename(columns={'is_in_growth_subset': 'label'})\n",
    "    \n",
    "    print(\"Labelling users...\")\n",
    "    user_features_final_stable = stable_labels.merge(user_features_final, on='user_id')\n",
    "    user_features_final_growth = growth_labels.merge(user_features_final, on='user_id')\n",
    "    \n",
    "    return user_features_final_stable, user_features_final_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6d7ed",
   "metadata": {},
   "source": [
    "### Final function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125efa4e",
   "metadata": {},
   "source": [
    "Takes about 8 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e808d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating user_features...\n",
      "Generating user_features_2...\n",
      "Generating user_features_3...\n",
      "Generating user_features_4...\n",
      "Generating user_features_5...\n",
      "Generating user_features_6...\n",
      "Generating user_features_7...\n",
      "Generating user_features_8...\n",
      "Encoding categorical variables...\n",
      "The categorical variables to be encoded are\n",
      "['label_by_avg_bal', 'label_by_first_bal', 'label_by_last_bal', 'trend']\n",
      "Labelling users...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Arguments:\n",
    "# train: last 90 days bank balance data\n",
    "# user_features: initial features exported from oliver's EDA code\n",
    "# user_labels: labels generated from actual next 180 days data (subsetting methodology)\n",
    "\n",
    "def get_user_subsets_w_features(train, user_labels):\n",
    "    user_features_final = get_all_user_features(train)\n",
    "    \n",
    "    # Dataframe with entire dataset's users\n",
    "#     df = user_features_final.merge(user_labels[['user_id', 'text_label', 'label']], on='user_id')\n",
    "#     df.to_csv(\"user_features_l90_labelled_20231111.csv\", index=False)\n",
    "    \n",
    "    # Split into 2 dataframes\n",
    "    # user_features_final_stable: stable & non-stable users; user_features_final_growth: growth & non-growth users\n",
    "    user_features_final_stable, user_features_final_growth = label_users(user_labels, user_features_final)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return user_features_final_stable, user_features_final_growth\n",
    "\n",
    "\n",
    "user_features_final_stable, user_features_final_growth = get_user_subsets_w_features(train, user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292c30e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'label', 'beta_normalized', 'avg_balance',\n",
       "       'first_day_balance', 'last_day_balance', 'label_by_avg_bal',\n",
       "       'label_by_first_bal', 'label_by_last_bal', 'volatility_stdev',\n",
       "       'volatility_cv', 'stability_index', 'ema_7day', 'ema_20day',\n",
       "       'ema_50day', 'ema_90day', 'stat_sig_positive_kendall',\n",
       "       'num_ema_crosses', 'stationary', 'num_distinct_recurring_tx',\n",
       "       'recurring_transactions', 'recurring_deposits', 'recurring_withdrawals',\n",
       "       'income', 'subscription', 'abs_bal_change_mean', 'abs_bal_change_std',\n",
       "       'transactions', 'deposits', 'withdrawals', 'withdrawal_propn',\n",
       "       'deposit_propn', 'growth_coeff', 'trend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_final_stable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43bd1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>beta_normalized</th>\n",
       "      <th>avg_balance</th>\n",
       "      <th>first_day_balance</th>\n",
       "      <th>last_day_balance</th>\n",
       "      <th>label_by_avg_bal</th>\n",
       "      <th>label_by_first_bal</th>\n",
       "      <th>label_by_last_bal</th>\n",
       "      <th>volatility_stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>subscription</th>\n",
       "      <th>abs_bal_change_mean</th>\n",
       "      <th>abs_bal_change_std</th>\n",
       "      <th>transactions</th>\n",
       "      <th>deposits</th>\n",
       "      <th>withdrawals</th>\n",
       "      <th>withdrawal_propn</th>\n",
       "      <th>deposit_propn</th>\n",
       "      <th>growth_coeff</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000102c03057f91c90faa1011e59870f2f8710597c27b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>74243.627143</td>\n",
       "      <td>167126.280</td>\n",
       "      <td>76336.380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>60422.271064</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1008.776667</td>\n",
       "      <td>28910.758769</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>62.104009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001c00642af4db4bfab49d3884b5e88f72acddc4cb03b...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010642</td>\n",
       "      <td>11684.816374</td>\n",
       "      <td>13194.525</td>\n",
       "      <td>10103.580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>986.278778</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.343833</td>\n",
       "      <td>223.112578</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-33.024575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003c76e33adfa3484f6f8426d6f840cdaaade5bf71a2a...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070451</td>\n",
       "      <td>4057.439505</td>\n",
       "      <td>4813.635</td>\n",
       "      <td>3654.630</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>566.227093</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.877833</td>\n",
       "      <td>126.482115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.594144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003e52fe559c035a21c6b38b6f16612a6689ea555480e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>4035.443736</td>\n",
       "      <td>1716.795</td>\n",
       "      <td>371.385</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5367.771943</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.949000</td>\n",
       "      <td>3896.685693</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>-82.188555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004d0051f38ca5c9df27bca501d556fd16fa9acd2df39...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.051477</td>\n",
       "      <td>20042.205824</td>\n",
       "      <td>35462.130</td>\n",
       "      <td>6178.560</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17251.215708</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-325.373000</td>\n",
       "      <td>8107.574099</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-387.819611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50449</th>\n",
       "      <td>fff76a8dfb3e78fe545169ce8427012d783ab7f51e9fe1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049060</td>\n",
       "      <td>13735.436538</td>\n",
       "      <td>9399.855</td>\n",
       "      <td>4564.485</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9317.807627</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-53.726333</td>\n",
       "      <td>4720.654310</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>-156.302523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50450</th>\n",
       "      <td>fff798878bc2bb60ead2b2c405bc1c4bdc1b1ff713a422...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018823</td>\n",
       "      <td>9551.249505</td>\n",
       "      <td>19041.975</td>\n",
       "      <td>6706.125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12446.873858</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-137.065000</td>\n",
       "      <td>7312.832971</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>-249.323867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50451</th>\n",
       "      <td>fff7d14c2d27b7ba9c8c2e06940d38d17566b7ae04f208...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.252986</td>\n",
       "      <td>26218.259670</td>\n",
       "      <td>8337.045</td>\n",
       "      <td>60026.925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14137.128317</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>574.332000</td>\n",
       "      <td>8400.989160</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>295.022048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50452</th>\n",
       "      <td>fffae87c8a91a689bac61b5451f1f9887e681ccd723013...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150597</td>\n",
       "      <td>136050.193681</td>\n",
       "      <td>127841.040</td>\n",
       "      <td>129165.840</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>91483.292503</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.720000</td>\n",
       "      <td>29363.968737</td>\n",
       "      <td>78</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>-2420.956036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50453</th>\n",
       "      <td>ffff10e7cfb57aec0f3f16b43446b0ca83df037706f662...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>2811.539505</td>\n",
       "      <td>3.435</td>\n",
       "      <td>1515.195</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3619.875747</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16.797333</td>\n",
       "      <td>1131.175454</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>91.562525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50454 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 user_id  label  \\\n",
       "0      0000102c03057f91c90faa1011e59870f2f8710597c27b...      0   \n",
       "1      0001c00642af4db4bfab49d3884b5e88f72acddc4cb03b...      0   \n",
       "2      0003c76e33adfa3484f6f8426d6f840cdaaade5bf71a2a...      0   \n",
       "3      0003e52fe559c035a21c6b38b6f16612a6689ea555480e...      0   \n",
       "4      0004d0051f38ca5c9df27bca501d556fd16fa9acd2df39...      0   \n",
       "...                                                  ...    ...   \n",
       "50449  fff76a8dfb3e78fe545169ce8427012d783ab7f51e9fe1...      0   \n",
       "50450  fff798878bc2bb60ead2b2c405bc1c4bdc1b1ff713a422...      0   \n",
       "50451  fff7d14c2d27b7ba9c8c2e06940d38d17566b7ae04f208...      0   \n",
       "50452  fffae87c8a91a689bac61b5451f1f9887e681ccd723013...      0   \n",
       "50453  ffff10e7cfb57aec0f3f16b43446b0ca83df037706f662...      0   \n",
       "\n",
       "       beta_normalized    avg_balance  first_day_balance  last_day_balance  \\\n",
       "0             0.104897   74243.627143         167126.280         76336.380   \n",
       "1            -0.010642   11684.816374          13194.525         10103.580   \n",
       "2            -0.070451    4057.439505           4813.635          3654.630   \n",
       "3             0.022626    4035.443736           1716.795           371.385   \n",
       "4            -0.051477   20042.205824          35462.130          6178.560   \n",
       "...                ...            ...                ...               ...   \n",
       "50449         0.049060   13735.436538           9399.855          4564.485   \n",
       "50450         0.018823    9551.249505          19041.975          6706.125   \n",
       "50451        -0.252986   26218.259670           8337.045         60026.925   \n",
       "50452         0.150597  136050.193681         127841.040        129165.840   \n",
       "50453         0.036029    2811.539505              3.435          1515.195   \n",
       "\n",
       "       label_by_avg_bal  label_by_first_bal  label_by_last_bal  \\\n",
       "0                     0                   5                  0   \n",
       "1                     1                   1                  1   \n",
       "2                     4                   4                  4   \n",
       "3                     4                   4                  4   \n",
       "4                     1                   0                  1   \n",
       "...                 ...                 ...                ...   \n",
       "50449                 1                   1                  4   \n",
       "50450                 1                   1                  1   \n",
       "50451                 1                   1                  0   \n",
       "50452                 5                   5                  5   \n",
       "50453                 4                   4                  4   \n",
       "\n",
       "       volatility_stdev  ...  subscription  abs_bal_change_mean  \\\n",
       "0          60422.271064  ...             0         -1008.776667   \n",
       "1            986.278778  ...             0           -34.343833   \n",
       "2            566.227093  ...             0           -12.877833   \n",
       "3           5367.771943  ...             0           -14.949000   \n",
       "4          17251.215708  ...             0          -325.373000   \n",
       "...                 ...  ...           ...                  ...   \n",
       "50449       9317.807627  ...             0           -53.726333   \n",
       "50450      12446.873858  ...             0          -137.065000   \n",
       "50451      14137.128317  ...             0           574.332000   \n",
       "50452      91483.292503  ...             0            14.720000   \n",
       "50453       3619.875747  ...             0            16.797333   \n",
       "\n",
       "       abs_bal_change_std  transactions  deposits  withdrawals  \\\n",
       "0            28910.758769            63         7           56   \n",
       "1              223.112578             5         1            4   \n",
       "2              126.482115             1         0            1   \n",
       "3             3896.685693            52        18           34   \n",
       "4             8107.574099            24         6           18   \n",
       "...                   ...           ...       ...          ...   \n",
       "50449         4720.654310            35         8           27   \n",
       "50450         7312.832971            41        12           29   \n",
       "50451         8400.989160            44         7           37   \n",
       "50452        29363.968737            78        21           57   \n",
       "50453         1131.175454            11         5            6   \n",
       "\n",
       "       withdrawal_propn  deposit_propn  growth_coeff  trend  \n",
       "0              0.888889       0.111111     62.104009      1  \n",
       "1              0.800000       0.200000    -33.024575      0  \n",
       "2              1.000000       0.000000    -17.594144      0  \n",
       "3              0.653846       0.346154    -82.188555      0  \n",
       "4              0.750000       0.250000   -387.819611      0  \n",
       "...                 ...            ...           ...    ...  \n",
       "50449          0.771429       0.228571   -156.302523      0  \n",
       "50450          0.707317       0.292683   -249.323867      0  \n",
       "50451          0.840909       0.159091    295.022048      1  \n",
       "50452          0.730769       0.269231  -2420.956036      0  \n",
       "50453          0.545455       0.454545     91.562525      1  \n",
       "\n",
       "[50454 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_final_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c51da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export to csv if needed\n",
    "# user_features_final_growth.to_csv(\"user_features_l90_growth_20231111.csv\", index=False)\n",
    "# user_features_final_stable.to_csv(\"user_features_l90_stable_20231111.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
